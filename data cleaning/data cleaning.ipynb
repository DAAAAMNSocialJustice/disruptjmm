{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2d3fd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94d3b0",
   "metadata": {},
   "source": [
    "## Read in and process datafile with themes/codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8a570eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 327 users in the dataset\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Final Coding.csv\",keep_default_na=False)\n",
    "#The codes were in 5 different columns; lets aggregate them into a new column\n",
    "df[\"all codes\"] = df[[\"SO code\",\"BC code\",\"BtC code\",\"CCM code\",\"SJEDI code\"]].agg(';'.join,axis=1)\n",
    "#We separated them by ;, so convert to an array \n",
    "df[\"all codes\"] = df[\"all codes\"].apply(lambda s: s.split(';'))\n",
    "#Strip out leading/trailing spaces\n",
    "df[\"all codes\"] = df[\"all codes\"].apply(lambda s: [t.strip() for t in s if t])\n",
    "#Sort the arrays, so we can be confident the same things are not listed in two different ways\n",
    "df[\"all codes\"] = df[\"all codes\"].apply(sorted)\n",
    "#Convert back to string with ; between the codes\n",
    "df[\"all codes\"] = df[\"all codes\"].apply(lambda s: ';'.join(s))\n",
    "\n",
    "#Merge info on JMM attendance\n",
    "df_names = pd.read_csv(\"Names.csv\")\n",
    "df = df.merge(df_names,left_on='user_username',right_on='User Name',how='left')\n",
    "df=df.rename(columns={'In JMM 2020 Program?': 'At JMM 2020', 'In JMM 2021 Program': 'At JMM 2021', 'Too anonymous to determine':'Anonymous'})\n",
    "\n",
    "#Check merge\n",
    "print('There were ' + str(len(df['Display Name'].unique())) + ' users in the dataset')\n",
    "\n",
    "#Get mentions from tweet text\n",
    "df['Mentions']= df['text'].apply(lambda s: re.findall(\"\\B@\\w+\", s))\n",
    "\n",
    "#Get list of the codes\n",
    "codes = df['all codes'].apply(lambda s: s.split(';')).explode().unique()\n",
    "#Make a new column for each code, and mark it true/false if that code appears in 'all codes' column\n",
    "for code in codes:\n",
    "    df[code] = df['all codes'].apply(lambda s: code in s)\n",
    "\n",
    "\n",
    "#Make dictionaries of user_ids to usernamess, and tweetids to usernames\n",
    "users=df[['user_username','author_id']].drop_duplicates()        #Duplicates make python dictionaries upset\n",
    "user_dict = dict(zip(users['author_id'],users['user_username']))\n",
    "\n",
    "tweet_dict=dict(zip(df['tweet_id'],df['user_username']))\n",
    "\n",
    "\n",
    "#Lookup functions for tweetids and userids\n",
    "def tweeter_lookup(tweetid):\n",
    "    if tweetid == \"\":\n",
    "        return \"\"\n",
    "    elif int(tweetid) in tweet_dict.keys():\n",
    "        return tweet_dict[int(tweetid)]\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def lookup_username(s):\n",
    "    if s=='':\n",
    "        return ''\n",
    "    elif int(s) not in user_dict.keys():\n",
    "        return \"Error with id \"+str(s)\n",
    "    else:\n",
    "        return user_dict[int(s)]\n",
    "\n",
    "#Get receivers for replies\n",
    "df['Receiver']=''\n",
    "df['Receiver'].mask(df['in_reply_to_user_id']!='NA',df['in_reply_to_user_id'],inplace=True)\n",
    "df['Receiver'] = df['Receiver'].apply(lookup_username)\n",
    "\n",
    "#Get recievers for quote tweets and retweets\n",
    "df['sourcetweeter']=''\n",
    "df['sourcetweeter'].mask(df['sourcetweet_type']=='quoted', df['sourcetweet_id'],inplace=True )\n",
    "df['sourcetweeter'].mask(df['sourcetweet_type']=='retweeted', df['sourcetweet_id'],inplace=True )\n",
    "df['sourcetweeter']=df['sourcetweeter'].apply(tweeter_lookup)\n",
    "df['Receiver'].mask(df['sourcetweeter']!=\"\",df['sourcetweeter'],inplace=True)\n",
    "\n",
    "\n",
    "#Time binning\n",
    "df['date']=df['created_at'].apply(lambda s: str(s)[0:10])\n",
    "df[df['date']>'2020-01-16'].head(20)\n",
    "time_bins = ['Pre JMM 2020', 'JMM 2020', 'Inter JMM', 'JMM 2021', 'Post JMMs']\n",
    "#JMM 2020 time inverval: Jan 12 -- Jan 25\n",
    "#JMM 2021 time interval: Jan 3 -- Jan 16\n",
    "df[time_bins[0]]=False\n",
    "df[time_bins[0]].mask(df['date']<'2020-01-12',True,inplace=True)\n",
    "df[time_bins[1]]=False\n",
    "df[time_bins[1]].mask((df['date']>='2020-01-12') & (df['date']<='2020-01-25'),True,inplace=True)\n",
    "df[time_bins[2]]=False\n",
    "df[time_bins[2]].mask((df['date']>'2020-01-25') & (df['date']<'2021-01-03'),True,inplace=True)\n",
    "df[time_bins[3]]=False\n",
    "df[time_bins[3]].mask((df['date']>='2021-01-03') & (df['date']<='2021-01-16'),True,inplace=True)\n",
    "df[time_bins[4]]=False\n",
    "df[time_bins[4]].mask(df['date']>'2021-01-16',True,inplace=True)\n",
    "\n",
    "#Clean up the frame a bit\n",
    "df=df.drop(columns=['sourcetweeter'])\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv(\"all-data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85915b",
   "metadata": {},
   "source": [
    "## Codes by time bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fe222621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the codes in each time bin, store in a list.\n",
    "#Maybe there is a slicker way to get this into a df directly?\n",
    "codes_by_time=[]\n",
    "for time in time_bins:\n",
    "   codes_by_time.append(df.groupby([time]).sum()[codes].transpose()[True])\n",
    "\n",
    "#dataframe from the list\n",
    "cbtdf=pd.DataFrame(codes_by_time)\n",
    "#Labels\n",
    "cbtdf['times']=time_bins\n",
    "cbtdf.set_index('times',inplace=True)\n",
    "#Transpose for easier reading\n",
    "cbtdf.transpose().to_csv(\"codes-by-time-bucket.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06172eb",
   "metadata": {},
   "source": [
    "## Generate detailed edge list for people network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "10389fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up a bit\n",
    "df['Sender']=df['user_username']\n",
    "themes = ['Self-organization','Building community','Broadening the counterpublic','Creating change in math','SJEDI']\n",
    "#Convert themes 1/0 into True/False\n",
    "for column in themes:\n",
    "    df[column]=df[column].apply(bool)\n",
    "\n",
    "edges_verbose=df[df['Receiver']!=''].copy()\n",
    "#Include only tweets with a Receiver\n",
    "edges_verbose=edges_verbose[edges_verbose['Receiver'].str.contains('Error')==False]\n",
    "#Only the columns we need to make it a bit more manageable\n",
    "cols=['Sender','Receiver','text','created_at']+themes+codes.tolist()+time_bins\n",
    "\n",
    "edges_verbose[cols].to_csv(\"people-edge-list.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797441a",
   "metadata": {},
   "source": [
    "## People network with mention edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0dd30b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mentions column is a list, convert to one row for each person mentioned in the list\n",
    "mention_df=df.explode(['Mentions'])\n",
    "#Drop the rows with na, i.e. those that didn't mention anyone\n",
    "mention_df=mention_df[mention_df['Mentions'].notna()]\n",
    "#Mentions have an @ in front of usernames, drop this to match format of Receiver column\n",
    "mention_df['Mentions']=mention_df['Mentions'].apply(lambda s: str(s)[1:])\n",
    "#The first user mentioned in a reply is already represented as an edge, so drop from this set\n",
    "mention_df=mention_df[mention_df['Mentions']!=mention_df['Receiver']]\n",
    "mention_df['Receiver']=mention_df['Mentions']\n",
    "\n",
    "mention_df[cols].to_csv(\"people-nodes-mention-edge-list.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c87c2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
