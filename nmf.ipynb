{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da7f422-a9b1-4002-b466-3727c9eb570a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting NeuralNMF\n",
      "  Downloading NeuralNMF-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting torch (from NeuralNMF)\n",
      "  Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from NeuralNMF) (3.10.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from NeuralNMF) (1.13.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from NeuralNMF) (1.26.4)\n",
      "Collecting fnnls (from NeuralNMF)\n",
      "  Downloading fnnls-1.0.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from NeuralNMF) (4.67.1)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.12/site-packages (from fnnls->NeuralNMF) (8.3.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (75.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (2024.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->NeuralNMF) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch->NeuralNMF) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->NeuralNMF) (3.0.2)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/lib/python3.12/site-packages (from pytest->fnnls->NeuralNMF) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from pytest->fnnls->NeuralNMF) (1.5.0)\n",
      "Downloading NeuralNMF-1.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading fnnls-1.0.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: torch, fnnls, NeuralNMF\n",
      "Successfully installed NeuralNMF-1.0.0 fnnls-1.0.0 torch-2.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install NeuralNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bfe3046-993a-45ab-aec3-d406dc1c919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6572e971-8d98-4a95-ae7a-c078e5067301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Anyone feel like looking through the list of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"If you think that your right to speech is mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I ran at elevation to make it to user308 s #Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>user172 user308 user36 Here!!! #disruptJMM you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>user308 user36 Where and what? - let's get the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>1124</td>\n",
       "      <td>RT user266  AMS-AWM invited session on Mathema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1125</td>\n",
       "      <td>RT user266  AMS-AWM invited session on Mathema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1126</td>\n",
       "      <td>RT user246  “[C]arry some of this weight with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>1127</td>\n",
       "      <td>RT user75  Kelly MacArthur now speaking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>1128</td>\n",
       "      <td>RT user75  The stereotype of a mathematician i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text\n",
       "0              0  Anyone feel like looking through the list of i...\n",
       "1              1  \"If you think that your right to speech is mor...\n",
       "2              2  I ran at elevation to make it to user308 s #Di...\n",
       "3              3  user172 user308 user36 Here!!! #disruptJMM you...\n",
       "4              4  user308 user36 Where and what? - let's get the...\n",
       "...          ...                                                ...\n",
       "1124        1124  RT user266  AMS-AWM invited session on Mathema...\n",
       "1125        1125  RT user266  AMS-AWM invited session on Mathema...\n",
       "1126        1126  RT user246  “[C]arry some of this weight with ...\n",
       "1127        1127  RT user75  Kelly MacArthur now speaking about ...\n",
       "1128        1128  RT user75  The stereotype of a mathematician i...\n",
       "\n",
       "[1129 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('text_of_tweets.csv')\n",
    "\n",
    "\n",
    "# Remove hashtags from text column (assuming column name is 'text')\n",
    "#df['text_clean'] = df['text'].apply(lambda x: re.sub(r'#\\w+', '', x).strip())\n",
    "\n",
    "# Remove multiple spaces created by removing hashtags\n",
    "#df['text_clean'] = df['text_clean'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "#print(\"Original text with hashtags:\")\n",
    "#print(df['text'].head())\n",
    "#print(\"\\nClean text without hashtags:\")\n",
    "#print(df['text_clean'].head())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2f57e1-722d-4e6c-beb9-32187f9547f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"text\"])\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d0c0332-af48-4906-bce1-809329e2bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '10' '11' ... 'yore' 'yt' '春节快乐']\n",
      "  (0, 93)\t0.20844361686195892\n",
      "  (0, 552)\t0.2443122815321362\n",
      "  (0, 848)\t0.18591668295128036\n",
      "  (0, 861)\t0.2517803855866228\n",
      "  (0, 852)\t0.24789056739634663\n",
      "  (0, 773)\t0.21507868983383877\n",
      "  (0, 1445)\t0.2517803855866228\n",
      "  (0, 787)\t0.11160903261423519\n",
      "  (0, 1267)\t0.2013326761550325\n",
      "  (0, 993)\t0.2870281415549899\n",
      "  (0, 844)\t0.271986248508198\n",
      "  (0, 1104)\t0.2870281415549899\n",
      "  (0, 608)\t0.2560411993324567\n",
      "  (0, 671)\t0.2116381689719567\n",
      "  (0, 419)\t0.05992101213489889\n",
      "  (0, 179)\t0.3098644518414129\n",
      "  (0, 1442)\t0.12536211478983486\n",
      "  (0, 1424)\t0.271986248508198\n",
      "  (0, 1487)\t0.19083424083801917\n",
      "  (1, 787)\t0.10270189633549034\n",
      "  (1, 419)\t0.055138920501772465\n",
      "  (1, 1471)\t0.16940001303249466\n",
      "  (1, 1244)\t0.20920349544224195\n",
      "  (1, 1355)\t0.22176597351779717\n",
      "  (1, 719)\t0.16121988971151957\n",
      "  :\t:\n",
      "  (1126, 1710)\t0.41557560532596416\n",
      "  (1126, 1472)\t0.4086599594993448\n",
      "  (1126, 1608)\t0.391161394548689\n",
      "  (1127, 1662)\t0.18012412293640256\n",
      "  (1127, 175)\t0.2890664199591968\n",
      "  (1127, 807)\t0.29857091227983185\n",
      "  (1127, 1353)\t0.26243688528626524\n",
      "  (1127, 869)\t0.31716451319702754\n",
      "  (1127, 1704)\t0.2890664199591968\n",
      "  (1127, 1740)\t0.2651108242936943\n",
      "  (1127, 1210)\t0.31716451319702754\n",
      "  (1127, 509)\t0.31716451319702754\n",
      "  (1127, 212)\t0.2936023562409412\n",
      "  (1127, 330)\t0.2890664199591968\n",
      "  (1127, 1295)\t0.31716451319702754\n",
      "  (1128, 419)\t0.07719521619779159\n",
      "  (1128, 1662)\t0.19899652118692618\n",
      "  (1128, 616)\t0.30650182993629116\n",
      "  (1128, 1384)\t0.36977345096083725\n",
      "  (1128, 885)\t0.33592145832560477\n",
      "  (1128, 827)\t0.36977345096083725\n",
      "  (1128, 984)\t0.25296770556011233\n",
      "  (1128, 180)\t0.36977345096083725\n",
      "  (1128, 705)\t0.36977345096083725\n",
      "  (1128, 246)\t0.36977345096083725\n",
      "Document-Topic Matrix:\n",
      " [[0.00155989 0.00966236 0.         0.06041711]\n",
      " [0.         0.         0.01863963 0.08342628]\n",
      " [0.00766356 0.01485521 0.00114966 0.03366586]\n",
      " ...\n",
      " [0.00916767 0.         0.00047038 0.04250933]\n",
      " [0.         0.         0.         0.01279858]\n",
      " [0.00750037 0.0001448  0.00062253 0.02903424]]\n",
      "Topic-Word Matrix:\n",
      " [[0.00000000e+00 3.35005390e-04 1.36922246e-02 ... 2.99453012e-05\n",
      "  1.38254690e-04 3.42182008e-05]\n",
      " [6.98553230e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  5.80057965e-04 0.00000000e+00]\n",
      " [0.00000000e+00 6.56918035e-05 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.49036417e-03 1.26072575e-03 3.82236689e-03 ... 9.20083581e-04\n",
      "  5.03359000e-03 1.19264649e-03]]\n",
      "*********************************************\n",
      "Names in Group: 1\n",
      "disruptjmm\n",
      "user172\n",
      "*********************************************\n",
      "Names in Group: 2\n",
      "anti\n",
      "di\n",
      "dr\n",
      "erica\n",
      "graham\n",
      "jmm2021\n",
      "mathematics\n",
      "racism\n",
      "talk\n",
      "user197\n",
      "user266\n",
      "*********************************************\n",
      "Names in Group: 3\n",
      "deadline\n",
      "disruptjmm\n",
      "extended\n",
      "heels\n",
      "interested\n",
      "know\n",
      "might\n",
      "pcmi\n",
      "programs\n",
      "several\n",
      "summer\n",
      "user112\n",
      "*********************************************\n",
      "Names in Group: 4\n",
      "asking\n",
      "binary\n",
      "challenge\n",
      "come\n",
      "consider\n",
      "disruptjmm\n",
      "disruptmath\n",
      "diversityandinclusion\n",
      "fundamental\n",
      "honor\n",
      "hope\n",
      "important\n",
      "jmm2020\n",
      "jmm2021\n",
      "key\n",
      "math\n",
      "mathematical\n",
      "might\n",
      "morning\n",
      "neutral\n",
      "non\n",
      "panel\n",
      "people\n",
      "question\n",
      "quoting\n",
      "saturday\n",
      "students\n",
      "supporting\n",
      "talk\n",
      "things\n",
      "think\n",
      "time\n",
      "trans\n",
      "two\n",
      "us\n",
      "user10\n",
      "user102\n",
      "user184\n",
      "user250\n",
      "user266\n",
      "user279\n",
      "user36\n",
      "user75\n",
      "user76\n",
      "user78\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "groupNum=4\n",
    "documents=df[\"text\"]\n",
    "\n",
    "\n",
    "#documents=[\"I write something does this have to be really long\", \"I am so very lost bro, what's going on something else\"]\n",
    "\n",
    "#vectorizer=TfidfVectorizer(stop_words='english')\n",
    "stopwords_list=stopwords.words(\"english\")\n",
    "#stopwords_list+= [\"rt\", \"https://t.co/pIPCd6Nu9s\",\"https://t.co/DdGBGsLBKe\",\"pipcd6nu9s\", \"ddgbgslbke\", \"https\"]\n",
    "stopwords_list+= [\"rt\", \"RT\"]\n",
    "\n",
    "vectorizer=TfidfVectorizer(stop_words=stopwords_list, preprocessor=lambda s: re.sub(r'http.*\\s?', '',s).lower())\n",
    "X=vectorizer.fit_transform(documents)\n",
    "names=vectorizer.get_feature_names_out()\n",
    "print(names)\n",
    "n=len(names)\n",
    "print(X)\n",
    "\n",
    "nmf=NMF(n_components=groupNum, max_iter=10000,l1_ratio=0)\n",
    "W=nmf.fit_transform(X)\n",
    "H=nmf.components_\n",
    "\n",
    "print(\"Document-Topic Matrix:\\n\", W)\n",
    "print(\"Topic-Word Matrix:\\n\", H)\n",
    "\n",
    "for i in range(groupNum):\n",
    "    print(\"*********************************************\")\n",
    "    print(\"Names in Group:\", i+1)\n",
    "    for j in range(n):\n",
    "        if H[i,j]>.1:\n",
    "            print(names[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5658ad9-c2bf-49e5-a0d7-cb15beaca092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from NeuralNMF import Neural_NMF\n",
    "X = 10*torch.mm(torch.randn(100,5),torch.randn(5,20)) #produce random low rank data\n",
    "m, k1, k2, = X.shape[0], 10, 5\n",
    "net = Neural_NMF([m, k1, k2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a687405-657c-49d5-843c-6ad891a2703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 48.00it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m history \u001b[38;5;241m=\u001b[39m train(net, X, epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m epoch \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m----> 4\u001b[0m tensor(\u001b[38;5;241m485.2435\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m      5\u001b[0m epoch \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m2\u001b[39m \n\u001b[1;32m      6\u001b[0m tensor(\u001b[38;5;241m475.1584\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "from NeuralNMF import train\n",
    "history = train(net, X, epoch=6, lr=500, supervised=False)\n",
    "epoch =  1 \n",
    "tensor(485.2435, dtype=torch.float64)\n",
    "epoch =  2 \n",
    "tensor(475.1584, dtype=torch.float64)\n",
    "epoch =  3 \n",
    "tensor(461.2400, dtype=torch.float64)\n",
    "epoch =  4 \n",
    "tensor(444.1705, dtype=torch.float64)\n",
    "epoch =  5 \n",
    "tensor(430.4947, dtype=torch.float64)\n",
    "epoch =  6 \n",
    "tensor(422.7317, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fdb365-31c3-457b-8854-e00021f16471",
   "metadata": {},
   "source": [
    "Tutorial time!!!! from Medium article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb99f24-1d07-4d60-af87-eb1f81b604ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63174505 0.         0.         0.4804584  0.4804584  0.\n",
      "  0.37311881 0.        ]\n",
      " [0.         0.54645401 0.         0.         0.         0.54645401\n",
      "  0.32274454 0.54645401]\n",
      " [0.         0.         0.63174505 0.4804584  0.4804584  0.\n",
      "  0.37311881 0.        ]]\n",
      "(3, 8)\n",
      "['banana' 'blueberry' 'coconut' 'mango' 'pineapple' 'raspberry' 'smoothie'\n",
      " 'strawberry']\n",
      "NMF(n_components=2, random_state=42)\n",
      "Document-Topic Matrix:\n",
      " [[6.27920439e-01 2.89477799e-17]\n",
      " [1.81158550e-17 8.23117356e-01]\n",
      " [6.27920439e-01 1.14221590e-17]]\n",
      "Topic-Word Matrix:\n",
      " [[0.50304546 0.         0.50304546 0.76515808 0.76515808 0.\n",
      "  0.59421351 0.        ]\n",
      " [0.         0.66388348 0.         0.         0.         0.66388348\n",
      "  0.39210028 0.66388348]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"Mango, pineapple and banana smoothie.\",\n",
    "  \"Strawberry, blueberry and raspberry smoothie.\",\n",
    "    \"Mango, pineapple and coconut smoothie.\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(X.toarray())\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "nmf = NMF(n_components=2, random_state=42)\n",
    "print(nmf)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_\n",
    "\n",
    "print(\"Document-Topic Matrix:\\n\", W)\n",
    "print(\"Topic-Word Matrix:\\n\", H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e84e47d-d4fc-4c83-84a3-7c6da3f20621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.5178561161676974\n",
      "  (0, 4)\t0.5178561161676974\n",
      "  (0, 0)\t0.680918560398684\n",
      "  (1, 6)\t0.5773502691896257\n",
      "  (1, 1)\t0.5773502691896257\n",
      "  (1, 5)\t0.5773502691896257\n",
      "  (2, 3)\t0.5178561161676974\n",
      "  (2, 4)\t0.5178561161676974\n",
      "  (2, 2)\t0.680918560398684\n",
      "[[0.68091856 0.         0.         0.51785612 0.51785612 0.\n",
      "  0.        ]\n",
      " [0.         0.57735027 0.         0.         0.         0.57735027\n",
      "  0.57735027]\n",
      " [0.         0.         0.68091856 0.51785612 0.51785612 0.\n",
      "  0.        ]]\n",
      "(3, 7)\n",
      "['banana' 'blueberry' 'coconut' 'mango' 'pineapple' 'raspberry'\n",
      " 'strawberry']\n",
      "NMF(n_components=2, random_state=42)\n",
      "Document-Topic Matrix:\n",
      " [[0.52010624 0.        ]\n",
      " [0.         0.80515326]\n",
      " [0.52010624 0.        ]]\n",
      "Topic-Word Matrix:\n",
      " [[0.65459564 0.         0.65459564 0.99567372 0.99567372 0.\n",
      "  0.        ]\n",
      " [0.         0.71706878 0.         0.         0.         0.71706878\n",
      "  0.71706878]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"Mango, pineapple and banana.\",\n",
    "  \"Strawberry, blueberry and raspberry.\",\n",
    "    \"Mango, pineapple and coconut.\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(X)\n",
    "print(X.toarray())\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "nmf = NMF(n_components=2, random_state=42) ##Pick the rank, n_components is \n",
    "#2 in this case\n",
    "print(nmf)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_\n",
    "\n",
    "print(\"Document-Topic Matrix:\\n\", W)\n",
    "print(\"Topic-Word Matrix:\\n\", H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "231c0309-01c2-4e62-b0c3-87d4b2aab095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X2=np.array([[1,1,1,0,0,0,0],[0,0,0,1,1,1,0],[1,1,0,0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3780194e-a739-46b9-a4a2-cee2d25e8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF(n_components=2, random_state=42)\n",
      "Document-Topic Matrix:\n",
      " [[5.29056791e-01 2.71050543e-20]\n",
      " [0.00000000e+00 9.33743230e-01]\n",
      " [5.29056791e-01 2.71050543e-20]]\n",
      "Topic-Word Matrix:\n",
      " [[1.89015625 1.89015625 0.94507813 0.         0.         0.\n",
      "  0.94507813]\n",
      " [0.         0.         0.         1.07095823 1.07095823 1.07095823\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=2, random_state=42)\n",
    "print(nmf)\n",
    "W2 = nmf.fit_transform(X2)\n",
    "H2 = nmf.components_\n",
    "\n",
    "print(\"Document-Topic Matrix:\\n\", W2)\n",
    "print(\"Topic-Word Matrix:\\n\", H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4a1bbca-69e5-4faf-b465-851145e47ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.40546511, 1.40546511, 2.09861229, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 2.09861229, 2.09861229,\n",
       "        2.09861229, 0.        ],\n",
       "       [1.40546511, 1.40546511, 0.        , 0.        , 0.        ,\n",
       "        0.        , 2.09861229]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rachel=np.array([[np.log(3/2)+1,np.log(3/2)+1,np.log(3)+1,0,0,0,0],[\n",
    "    0,0,0,np.log(3)+1,np.log(3)+1,np.log(3)+1,0],\n",
    "              [np.log(3/2)+1,np.log(3/2)+1,0,0,0,0,np.log(3)+1]])\n",
    "\n",
    "Rachel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cce5c498-76df-4ea3-b137-ff11206b6b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48624042, 0.48624042, 0.72604443, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.57735027, 0.57735027,\n",
       "        0.57735027, 0.        ],\n",
       "       [0.48624042, 0.48624042, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.72604443]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "normalize(Rachel, norm=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d778170-46b1-4c59-a1a3-df57ade31c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "norm_berry=np.linalg.norm(Rachel,2,0)\n",
    "normed=[]\n",
    "for i in range(7):\n",
    "    Rachel[:,i]/norm_berry[i]\n",
    "print(Rachel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "331be645-35c9-44d9-ac0c-f473db159e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40546511, 0.        , 1.40546511])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab35fb-336c-474f-8d26-f1851b09c91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
