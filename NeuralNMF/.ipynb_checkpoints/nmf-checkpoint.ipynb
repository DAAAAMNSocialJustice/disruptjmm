{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da7f422-a9b1-4002-b466-3727c9eb570a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting NeuralNMF\n",
      "  Downloading NeuralNMF-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting torch (from NeuralNMF)\n",
      "  Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from NeuralNMF) (3.10.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from NeuralNMF) (1.13.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from NeuralNMF) (1.26.4)\n",
      "Collecting fnnls (from NeuralNMF)\n",
      "  Downloading fnnls-1.0.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from NeuralNMF) (4.67.1)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.12/site-packages (from fnnls->NeuralNMF) (8.3.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->NeuralNMF) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (75.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch->NeuralNMF) (2024.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->NeuralNMF) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch->NeuralNMF) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->NeuralNMF) (3.0.2)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/lib/python3.12/site-packages (from pytest->fnnls->NeuralNMF) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from pytest->fnnls->NeuralNMF) (1.5.0)\n",
      "Downloading NeuralNMF-1.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading fnnls-1.0.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: torch, fnnls, NeuralNMF\n",
      "Successfully installed NeuralNMF-1.0.0 fnnls-1.0.0 torch-2.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install NeuralNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bfe3046-993a-45ab-aec3-d406dc1c919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import csv #Do I need this one?\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6572e971-8d98-4a95-ae7a-c078e5067301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id 0</td>\n",
       "      <td>anyone feel like looking list invited talk #jm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id 1</td>\n",
       "      <td>think right speech important another human wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id 10</td>\n",
       "      <td>anyone user10 working #disruptjmm become free ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id 100</td>\n",
       "      <td>im bar wynkoop anyone want join #disruptjmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id 1000</td>\n",
       "      <td>rtuser75 every clas culture youre intentional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>id 995</td>\n",
       "      <td>rtuser177 well put #disruptjmm #disruptmath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>id 996</td>\n",
       "      <td>rtuser172 #disruptjmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>id 997</td>\n",
       "      <td>rtuser172 #disruptjmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>id 998</td>\n",
       "      <td>rtuser75 here reading list go home work learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>id 999</td>\n",
       "      <td>rtuser70 now della dumbaugh hannah fenster mot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet                                               text\n",
       "0        id 0  anyone feel like looking list invited talk #jm...\n",
       "1        id 1  think right speech important another human wor...\n",
       "2       id 10  anyone user10 working #disruptjmm become free ...\n",
       "3      id 100        im bar wynkoop anyone want join #disruptjmm\n",
       "4     id 1000  rtuser75 every clas culture youre intentional ...\n",
       "...       ...                                                ...\n",
       "1124   id 995        rtuser177 well put #disruptjmm #disruptmath\n",
       "1125   id 996                              rtuser172 #disruptjmm\n",
       "1126   id 997                              rtuser172 #disruptjmm\n",
       "1127   id 998  rtuser75 here reading list go home work learni...\n",
       "1128   id 999  rtuser70 now della dumbaugh hannah fenster mot...\n",
       "\n",
       "[1129 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data cleaning/tweets_el.csv',names=[\"tweet_id\",\"word\"]) \n",
    "#the .. moves up the directory then down to the right file. \n",
    "df\n",
    "tweets = df.groupby('tweet_id')['word'].apply(lambda x: ' '.join(x.astype(str))).reset_index()\n",
    "tweets.columns = ['tweet', 'text']\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b2f57e1-722d-4e6c-beb9-32187f9547f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0c0332-af48-4906-bce1-809329e2bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '11270' '12' ... 'youve' 'yt' '春节快乐']\n",
      "  (0, 101)\t0.2044843428916866\n",
      "  (0, 537)\t0.23595635548102983\n",
      "  (0, 828)\t0.18882702734562706\n",
      "  (0, 841)\t0.2557217620256081\n",
      "  (0, 833)\t0.25177105252431353\n",
      "  (0, 757)\t0.21844553701164354\n",
      "  (0, 1442)\t0.2508249696642172\n",
      "  (0, 772)\t0.11335616319590772\n",
      "  (0, 1279)\t0.1994341967082759\n",
      "  (0, 960)\t0.2915212872454883\n",
      "  (0, 823)\t0.27624392802958153\n",
      "  (0, 1066)\t0.2915212872454883\n",
      "  (0, 590)\t0.26004927465614514\n",
      "  (0, 652)\t0.2132999028508951\n",
      "  (0, 407)\t0.06057752513977303\n",
      "  (0, 182)\t0.314715077703\n",
      "  (0, 1426)\t0.27624392802958153\n",
      "  (0, 1481)\t0.1907594260602895\n",
      "  (1, 772)\t0.10308094806031448\n",
      "  (1, 407)\t0.05508645093927074\n",
      "  (1, 1468)\t0.17002523388445873\n",
      "  (1, 1196)\t0.20997562281881524\n",
      "  (1, 1361)\t0.222584466435344\n",
      "  (1, 700)\t0.16181491939891193\n",
      "  (1, 95)\t0.21220799381680772\n",
      "  :\t:\n",
      "  (1126, 407)\t0.3762865485248141\n",
      "  (1126, 1215)\t0.9265033369606841\n",
      "  (1127, 833)\t0.35923602801232707\n",
      "  (1127, 772)\t0.16174066640676468\n",
      "  (1127, 407)\t0.08643420003944825\n",
      "  (1127, 1544)\t0.23164620278316345\n",
      "  (1127, 1253)\t0.22657664958583543\n",
      "  (1127, 1151)\t0.3143306241432393\n",
      "  (1127, 594)\t0.32946531636495147\n",
      "  (1127, 654)\t0.3648730429703456\n",
      "  (1127, 669)\t0.37104769423775913\n",
      "  (1127, 1704)\t0.3143306241432393\n",
      "  (1127, 813)\t0.39415481038387734\n",
      "  (1128, 407)\t0.06930066304051916\n",
      "  (1128, 1251)\t0.2459040336622347\n",
      "  (1128, 972)\t0.1888390928564779\n",
      "  (1128, 362)\t0.33350022883773556\n",
      "  (1128, 435)\t0.33350022883773556\n",
      "  (1128, 626)\t0.33350022883773556\n",
      "  (1128, 541)\t0.33350022883773556\n",
      "  (1128, 917)\t0.33350022883773556\n",
      "  (1128, 344)\t0.33350022883773556\n",
      "  (1128, 436)\t0.30296897446799154\n",
      "  (1128, 863)\t0.2268033982268701\n",
      "  (1128, 866)\t0.2974962597975896\n",
      "Document-Topic Matrix:\n",
      " [[0.00145405 0.02233208 0.         0.06440905]\n",
      " [0.         0.00055922 0.01956486 0.07890894]\n",
      " [0.00312698 0.         0.         0.02882566]\n",
      " ...\n",
      " [0.32259247 0.         0.         0.        ]\n",
      " [0.00246946 0.         0.         0.07797585]\n",
      " [0.0070382  0.022774   0.00133044 0.01753194]]\n",
      "Topic-Word Matrix:\n",
      " [[3.01772653e-04 1.82526125e-02 0.00000000e+00 ... 0.00000000e+00\n",
      "  1.54029258e-04 5.19087631e-05]\n",
      " [0.00000000e+00 5.88238987e-05 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.05575337e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.52070546e-03 4.13613566e-03 2.62866694e-03 ... 8.24233453e-03\n",
      "  5.27597084e-03 1.01610718e-03]]\n",
      "*********************************************\n",
      "Names in Group: 1\n",
      "disruptjmm\n",
      "rtuser172\n",
      "*********************************************\n",
      "Names in Group: 2\n",
      "antiracism\n",
      "di\n",
      "dr\n",
      "erica\n",
      "graham\n",
      "jmm2021\n",
      "mathematic\n",
      "now\n",
      "rtuser266\n",
      "talk\n",
      "user197\n",
      "*********************************************\n",
      "Names in Group: 3\n",
      "deadline\n",
      "disruptjmm\n",
      "extended\n",
      "heel\n",
      "interested\n",
      "know\n",
      "might\n",
      "pcmi\n",
      "program\n",
      "rtuser112\n",
      "several\n",
      "summer\n",
      "*********************************************\n",
      "Names in Group: 4\n",
      "asking\n",
      "can\n",
      "challenge\n",
      "come\n",
      "consider\n",
      "disruptjmm\n",
      "disruptmath\n",
      "diversityandinclusion\n",
      "fundamental\n",
      "honor\n",
      "hope\n",
      "im\n",
      "important\n",
      "jmm2020\n",
      "just\n",
      "key\n",
      "math\n",
      "mathematical\n",
      "might\n",
      "morning\n",
      "need\n",
      "neutral\n",
      "nonbinary\n",
      "panel\n",
      "people\n",
      "question\n",
      "quoting\n",
      "rtuser250\n",
      "rtuser36\n",
      "rtuser75\n",
      "rtuser76\n",
      "rtuser78\n",
      "saturday\n",
      "student\n",
      "supporting\n",
      "talk\n",
      "thing\n",
      "think\n",
      "time\n",
      "tran\n",
      "two\n",
      "user10\n",
      "user102\n",
      "user266\n",
      "user279\n",
      "user36\n",
      "youre\n"
     ]
    }
   ],
   "source": [
    "groupNum=4\n",
    "documents=tweets[\"text\"]\n",
    "\n",
    "\n",
    "#documents=[\"I write something does this have to be really long\", \"I am so very lost bro, what's going on something else\"]\n",
    "\n",
    "#vectorizer=TfidfVectorizer(stop_words='english')\n",
    "#stopwords_list=stopwords.words(\"english\")\n",
    "#stopwords_list+= [\"rt\", \"https://t.co/pIPCd6Nu9s\",\"https://t.co/DdGBGsLBKe\",\"pipcd6nu9s\", \"ddgbgslbke\", \"https\"]\n",
    "#stopwords_list+= [\"rt\", \"RT\"]\n",
    "\n",
    "#vectorizer=TfidfVectorizer(stop_words=stopwords_list, preprocessor=lambda s: re.sub(r'http.*\\s?', '',s).lower())\n",
    "vectorizer=TfidfVectorizer()\n",
    "\n",
    "X=vectorizer.fit_transform(documents)\n",
    "names=vectorizer.get_feature_names_out()\n",
    "print(names)\n",
    "n=len(names)\n",
    "print(X)\n",
    "\n",
    "nmf=NMF(n_components=groupNum, max_iter=10000,l1_ratio=0)\n",
    "W=nmf.fit_transform(X)\n",
    "H=nmf.components_\n",
    "\n",
    "print(\"Document-Topic Matrix:\\n\", W)\n",
    "print(\"Topic-Word Matrix:\\n\", H)\n",
    "\n",
    "for i in range(groupNum):\n",
    "    print(\"*********************************************\")\n",
    "    print(\"Names in Group:\", i+1)\n",
    "    for j in range(n):\n",
    "        if H[i,j]>.1:\n",
    "            print(names[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5658ad9-c2bf-49e5-a0d7-cb15beaca092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from NeuralNMF import Neural_NMF\n",
    "X = 10*torch.mm(torch.randn(100,5),torch.randn(5,20)) #produce random low rank data\n",
    "m, k1, k2, = X.shape[0], 10, 5\n",
    "net = Neural_NMF([m, k1, k2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a687405-657c-49d5-843c-6ad891a2703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 48.00it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m history \u001b[38;5;241m=\u001b[39m train(net, X, epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m epoch \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m----> 4\u001b[0m tensor(\u001b[38;5;241m485.2435\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m      5\u001b[0m epoch \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m2\u001b[39m \n\u001b[1;32m      6\u001b[0m tensor(\u001b[38;5;241m475.1584\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "from NeuralNMF import train\n",
    "history = train(net, X, epoch=6, lr=500, supervised=False)\n",
    "epoch =  1 \n",
    "tensor(485.2435, dtype=torch.float64)\n",
    "epoch =  2 \n",
    "tensor(475.1584, dtype=torch.float64)\n",
    "epoch =  3 \n",
    "tensor(461.2400, dtype=torch.float64)\n",
    "epoch =  4 \n",
    "tensor(444.1705, dtype=torch.float64)\n",
    "epoch =  5 \n",
    "tensor(430.4947, dtype=torch.float64)\n",
    "epoch =  6 \n",
    "tensor(422.7317, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fdb365-31c3-457b-8854-e00021f16471",
   "metadata": {},
   "source": [
    "Tutorial time!!!! from Medium article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb99f24-1d07-4d60-af87-eb1f81b604ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63174505 0.         0.         0.4804584  0.4804584  0.\n",
      "  0.37311881 0.        ]\n",
      " [0.         0.54645401 0.         0.         0.         0.54645401\n",
      "  0.32274454 0.54645401]\n",
      " [0.         0.         0.63174505 0.4804584  0.4804584  0.\n",
      "  0.37311881 0.        ]]\n",
      "(3, 8)\n",
      "['banana' 'blueberry' 'coconut' 'mango' 'pineapple' 'raspberry' 'smoothie'\n",
      " 'strawberry']\n",
      "NMF(n_components=2, random_state=42)\n",
      "Document-Topic Matrix:\n",
      " [[6.27920439e-01 2.89477799e-17]\n",
      " [1.81158550e-17 8.23117356e-01]\n",
      " [6.27920439e-01 1.14221590e-17]]\n",
      "Topic-Word Matrix:\n",
      " [[0.50304546 0.         0.50304546 0.76515808 0.76515808 0.\n",
      "  0.59421351 0.        ]\n",
      " [0.         0.66388348 0.         0.         0.         0.66388348\n",
      "  0.39210028 0.66388348]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"Mango, pineapple and banana smoothie.\",\n",
    "  \"Strawberry, blueberry and raspberry smoothie.\",\n",
    "    \"Mango, pineapple and coconut smoothie.\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(X.toarray())\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "nmf = NMF(n_components=2, random_state=42)\n",
    "print(nmf)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_\n",
    "\n",
    "print(\"Document-Topic Matrix:\\n\", W)\n",
    "print(\"Topic-Word Matrix:\\n\", H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e84e47d-d4fc-4c83-84a3-7c6da3f20621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.5178561161676974\n",
      "  (0, 4)\t0.5178561161676974\n",
      "  (0, 0)\t0.680918560398684\n",
      "  (1, 6)\t0.5773502691896257\n",
      "  (1, 1)\t0.5773502691896257\n",
      "  (1, 5)\t0.5773502691896257\n",
      "  (2, 3)\t0.5178561161676974\n",
      "  (2, 4)\t0.5178561161676974\n",
      "  (2, 2)\t0.680918560398684\n",
      "[[0.68091856 0.         0.         0.51785612 0.51785612 0.\n",
      "  0.        ]\n",
      " [0.         0.57735027 0.         0.         0.         0.57735027\n",
      "  0.57735027]\n",
      " [0.         0.         0.68091856 0.51785612 0.51785612 0.\n",
      "  0.        ]]\n",
      "(3, 7)\n",
      "['banana' 'blueberry' 'coconut' 'mango' 'pineapple' 'raspberry'\n",
      " 'strawberry']\n",
      "NMF(n_components=2, random_state=42)\n",
      "Document-Topic Matrix:\n",
      " [[0.52010624 0.        ]\n",
      " [0.         0.80515326]\n",
      " [0.52010624 0.        ]]\n",
      "Topic-Word Matrix:\n",
      " [[0.65459564 0.         0.65459564 0.99567372 0.99567372 0.\n",
      "  0.        ]\n",
      " [0.         0.71706878 0.         0.         0.         0.71706878\n",
      "  0.71706878]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"Mango, pineapple and banana.\",\n",
    "  \"Strawberry, blueberry and raspberry.\",\n",
    "    \"Mango, pineapple and coconut.\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(X)\n",
    "print(X.toarray())\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "nmf = NMF(n_components=2, random_state=42) ##Pick the rank, n_components is \n",
    "#2 in this case\n",
    "print(nmf)\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_\n",
    "\n",
    "print(\"Document-Topic Matrix:\\n\", W)\n",
    "print(\"Topic-Word Matrix:\\n\", H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "231c0309-01c2-4e62-b0c3-87d4b2aab095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X2=np.array([[1,1,1,0,0,0,0],[0,0,0,1,1,1,0],[1,1,0,0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3780194e-a739-46b9-a4a2-cee2d25e8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF(n_components=2, random_state=42)\n",
      "Document-Topic Matrix:\n",
      " [[5.29056791e-01 2.71050543e-20]\n",
      " [0.00000000e+00 9.33743230e-01]\n",
      " [5.29056791e-01 2.71050543e-20]]\n",
      "Topic-Word Matrix:\n",
      " [[1.89015625 1.89015625 0.94507813 0.         0.         0.\n",
      "  0.94507813]\n",
      " [0.         0.         0.         1.07095823 1.07095823 1.07095823\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=2, random_state=42)\n",
    "print(nmf)\n",
    "W2 = nmf.fit_transform(X2)\n",
    "H2 = nmf.components_\n",
    "\n",
    "print(\"Document-Topic Matrix:\\n\", W2)\n",
    "print(\"Topic-Word Matrix:\\n\", H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4a1bbca-69e5-4faf-b465-851145e47ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.40546511, 1.40546511, 2.09861229, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 2.09861229, 2.09861229,\n",
       "        2.09861229, 0.        ],\n",
       "       [1.40546511, 1.40546511, 0.        , 0.        , 0.        ,\n",
       "        0.        , 2.09861229]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rachel=np.array([[np.log(3/2)+1,np.log(3/2)+1,np.log(3)+1,0,0,0,0],[\n",
    "    0,0,0,np.log(3)+1,np.log(3)+1,np.log(3)+1,0],\n",
    "              [np.log(3/2)+1,np.log(3/2)+1,0,0,0,0,np.log(3)+1]])\n",
    "\n",
    "Rachel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cce5c498-76df-4ea3-b137-ff11206b6b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48624042, 0.48624042, 0.72604443, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.57735027, 0.57735027,\n",
       "        0.57735027, 0.        ],\n",
       "       [0.48624042, 0.48624042, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.72604443]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "normalize(Rachel, norm=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d778170-46b1-4c59-a1a3-df57ade31c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "norm_berry=np.linalg.norm(Rachel,2,0)\n",
    "normed=[]\n",
    "for i in range(7):\n",
    "    Rachel[:,i]/norm_berry[i]\n",
    "print(Rachel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "331be645-35c9-44d9-ac0c-f473db159e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40546511, 0.        , 1.40546511])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab35fb-336c-474f-8d26-f1851b09c91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
